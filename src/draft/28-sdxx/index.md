---
title: '从零创建一个经典的深度学习网络'
date: '2022-03-09'
---

最近正在阅读[《深度学习入门》](https://book.douban.com/subject/30270959/)，号称从零创建一个经典的深度学习网络，写篇总结。

[中文版pdf](https://github.com/chapin666/books/blob/master/ai/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E9%AB%98%E6%B8%85%E4%B8%AD%E6%96%87%E7%89%88.pdf)

一些参考代码：https://github.com/hguomin/deep-learning-from-scratch

# 历程

第一章是讲了点 Python 语法，学过 Python 可以直接跳过。书中的环境是 Python 3.4 ，我的环境是 Python 3.8 ，目前还没有遇到坑。

第二章是讲感知机，通过修改感知机的权重可以实现与，与非和或门。

权重是用来衡量输入信号重要性的参数，而偏置则是衡量神经元被激活的容易程度的参数。

单个感知机无法表示异或门。可以通过实现多个感知机叠加实现。

单层感知机只能表示线性空间，而多层感知机可以表非线性空间。

第三章：神经网络

此前感知机的参数是人工设定的，但是寻找一组合适的参数是困难的，而神经网络解决了这个问题。

神经网络的作用是能够自动的从数据中学习到合适的权重参数。

感知机和神经网络的区别在于激活函数。

神经网络的激活函数必须使用非线性函数。如果使用线性函数的话，加深神经网络的层数就没有意义了。使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。

